This document is a compilation of various things I thought were important to note down.

This format goes as follows
* each section starts after a line of /
* the text after a # denotes the title of the section


////////////////////////////////////////////////////////////////////////////////////////////////////


# general questions

can i use the same packing for SIMD CPU GEMM kernels for SIMT GPU GEMM kernels?

what need to be done to increase TC utilization?



////////////////////////////////////////////////////////////////////////////////////////////////////

# hardware properties

80 Volta MPs
8 TC per MP
2048 threads per MP
64 warps per MP
96 KB shared memory per MP
48 KB shared memory per thread blocks
4608 KB of L2 

1 TC does 4x4x4 mat-mul, this results in 2*4^3 flops = 2^7 flops per TC

1 volta can do TC_per_MP * MP_per_volta * FLOPS_per_TC = 8 * 80 * 2^7 = 81,920 FLOPS per volta

1 wmma does 16x16x16 mat-mul, this results in 2*16^3 flops = 2^13 flops per wmma

////////////////////////////////////////////////////////////////////////////////////////////////////

# deductions from hardware properties

equation to determine number of bytes per wmma


    A takes (m_wmma)(k_wmma)(S_data_in)
    B takes (n_wmma)(k_wmma)(S_data_in)
    C takes (m_wmma)(n_wmma)(S_data_out)

total = (m_wmma)(k_wmma)(S_data_in) + (n_wmma)(k_wmma)(S_data_in) + (m_wmma)(n_wmma)(S_data_out)
      = (k_wmma) (S_data_in) (m_wmma+n_wmma) + (m_wmma)(n_wmma)(S_data_out)

thus in shgemm we get

    total = 2*512 + 1024 = 2048 bytes per wmma in shgemm

total wmma calls 

(m*n*k) / (wmma_m * wmma_n * wmma_k)


////////////////////////////////////////////////////////////////////////////////////////////////////

# ideas on shgemm

my approach:

each thread in a warp will get the same address of the result matrix

therefore we need equations to calculate the address

assumptions:
split shared memory by half
1 warp = 1 block
32 threads = 1 warp

to increase TC utilization, we ...


////////////////////////////////////////////////////////////////////////////////////////////////////


# info pulled from cuda docs


An exception is the case where all threads in a warp address the same shared memory address, 
resulting in a broadcast.

The fraction of cycles the tensor (HMMA / IMMA) pipe was active. The value represents an average 
over a time interval and is not an instantaneous value. Higher values indicate higher utilization 
of the Tensor Cores. An activity of 1 (100%) is equivalent to issuing a tensor instruction every 
other cycle for the entire time interval. An activity of 0.2 (20%) could indicate 20% of the SMs 
are at 100% utilization over the entire time period, 100% of the SMs are at 20% utilization over 
the entire time period, 100% of the SMs are at 100% utilization for 20% of the time period, or any 
combination in between (see DCGM_FI_PROF_SM_ACTIVE to help disambiguate these possibilities).


////////////////////////////////////////////////////////////////////////////////////////////////////

# scratch pad 

an avg 0.000071842 seconds to compute a 720x720x720 shgemm

thus (2*720^3) / (0.000071842 * 10^12) = 10.4 TFLOPS

10.4 / 119 ~= 9% of peak